# Variational_Auto_Encoder
## Basic knowledge to understand VAE in better way 
The key is to notice that any distribution in d dimensions can be generated by taking a set of d variables that are normally distributed and mapping them through a sufficiently complicated function. For example, say we wanted to construct a 2D random variable whose values lie on a ring. If z is 2D and normally distributed, g ( z ) = z/10 + z/ || z || is roughly a ring

![Density_approximation](https://user-images.githubusercontent.com/21220616/58219328-08202900-7d28-11e9-8a35-29a1659ffcc2.png)

Our model is representative of our dataset, we need to make sure that for every datapoint X in the dataset, there is one (or
many) settings of the latent variables which causes the model to generate something very similar to X.Formally, say we have a vector of latent variables z in a high-dimensional space Z which we can easily sample according to some probability density function (PDF) P ( z ) defined over Z

## Objective function 
![](http://latex.codecogs.com/gif.latex?P%28X%29%20%3D%20%5Cint%20P%28X%7Cz%3B%5CTheta%20%29P%28z%29dz)
